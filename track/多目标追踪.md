视频中的多目标追踪是在实际中应用十分广泛，比如人体运动分析、自动驾驶和视频监控，旨在找到视频一个视频内运动物体的一些最优轨迹。这是一个数据相关的任务，会在视频的每一帧使用一个外部检测器定位目标的边界框，然后使用一个追踪算法将帧间对应的检测框结合起来。这样数据结合的任务在出现遮蔽、目标失踪和和误警报时十分困难。因此，现有的方法通常会在一个很大的时间窗内使用多个候选轨迹，而非依靠两个连续帧。尽管有这样一些努力，但依然受困于大量和不正确的检测。

近年来深度学习在多项视觉任务——比如图像分类、语义分割和目标追踪——上都取得了领先的表现，但在多目标追踪领域想对于传统基于手工特征的的方法却不尽如人意。造成这种现象的原因是多方面的：

- 首先是多目标追踪的数据还十分地不充足，无法很好训练神经网络的大量参数，由于标记视频帧的巨大代价，仅有有限的数据能用于训练多目标追踪。
- 然后，现有的在图像分类数据集上训练的神经网络在区别细微差别物体和获取移动特征方面作用有限，而多目标追踪的成功依赖于目标表面和移动的有效使用，但这两个因素的共同学习在神经网络还未被深入研究。

为此文献[1]提出了Quad-CNN，学习在帧间使用外表和运动两者来关联检测，即在度量学习中结合检测的外表嵌入向量和它们序列特定基于移动的位置嵌入向量；另外，使用了多任务损失来学习物体关联和边界框回归，而整个网络也在一个统一的网络中端到端训练；此外，采取了修改的最小最大标签传播算法来为多目标追踪产生快速而稳健的数据关联。因此，在MOT挑战基准数据集上获得了令人瞩目的效果，尤其是对比基于深度神经网络的方法。