大多数基于深度学习的追踪器都很难以实时速度获得优异性能，本文提出Siamese-RPN，它：

- 用大规模图像对在线下端到端训练；
- 由用于提取特征的孪生子网络，和包含分类和回归分支的区域推介子网络i组成；
- 在推理阶段这个框架被形式化为一个局部单射检测任务；
- 可以预先计算孪生子网络的模板分支，并形式化关联层为细小卷积层来执行在线追踪。





#### 以单射检测来追踪

将单射检测看成是一个判别性任务，其目标是找到使预测器函数$\psi(x; W)$的平均损失$\mathcal L$最小的参数$W$，并基于一个有$n$样本$x_i$及对应标签$\ell_i$的数据集计算：
$$
\min_W \frac1n \sum_{i=1}^n \mathcal L(\psi(x_i;W), \ell_i)
$$
单射学习旨在从兴趣类别的单个模板$z$中学习$W$，判别性单射学习的难题在于找到一个将类别信息包含进学习器的机制，即学习如何学习。为此作者提出一种使用元学习过程来从单个模板$z$中学习预测器参数$W$的方法，也就是一个将$\left(z; W'\right)$映射到$W$的前向函数$\omega$。令$z_i$为batch中的模板样本，则就能将这个问题形式化为：
$$
\min_{W'} \frac1n \sum_{i=1}^n \mathcal L\left( \psi(x_i; \omega(z_i; W')), \ell_i \right)
$$
与上面类似，令$z$表示模板块(patch)，$x$表示检测块，函数$\varphi$为孪生特征提取子网络，函数$\zeta$为区域提议子网络，则单射检测任务就恩那个形式化为：
$$
\min_W\frac1n\sum_{i=1}^n \mathcal L\left( \zeta(\varphi(x_i;W); \varphi(z_i; W)), \ell_i \right)
$$
现在就能将孪生子网络中的模板分支重新解读为训练参数来预测局部检测任务的核(kernel)，而这正是典型的学习如何学习过程。在这种解读中：

- 模板分支被用于将种类(category)嵌入(embed)到核中；
- 而检测分支则使用嵌入的信息执行检测。

在训练阶段，元学习器(meta leaner)仅需逐对(pair-wise)边框监督；在推理阶段，除初始帧外孪生框架被剪为仅剩检测分支一提高速度。第一帧的目标块被送入模板分支来预先计算检测核，这样在后面的帧就能执行单射检测。因为检测任务仅基于初始帧给出的模板信息，因此可以认为是一个单射检测。

##### 推理阶段：执行单射检测

如上所述，将模板分支的输出看成是局部检测的核，无论是特征提取或是区域提议其核都在初始帧上预先计算并在整个追踪阶段保持不变。通过对当前特征映射用预先计算的核进行卷积，检测分支想单射检测一样执行在线推断，如下图所示：

<img src='figures/tracking.png' />



在检测分支上执行前向传播就能获得分类和回归输出，这样就得到了前$M$个提议，这样就可以：

- 将分类特征图记为点集$A_{w\times h\times 2k}^{cls} = \left\{ \left( x_i^{cls}, y_j^{cls}, c_l^{cls} \right) \right\}$，其中$i\in[0,w), j\in[0,h), l\in[0,2k)$；
- 将回归特征图记为点集$A_{w\times h\times 4k}^{reg} = \left\{ \left( x_i^{reg}, y_j^{reg}, dx_p^{reg}, dy_p^{reg}, dw_p^{reg}, dh_p^{reg} \right) \right\}$，其中$i\in[0,w), j\in[0,h), p\in[0,k)$；

因为分类特征图的奇数通道表示正激活，因此收集所有$A_{w\times h\times 2k}^{cls}$中$l$为奇数的前$K$个点，并记这个点集为$CLS^*=\left\{ \left( x_i^{cls}, y_j^{cls}, c_l^{cls} \right)_{i\in I, j\in J, l\in L} \right\}$，其中$I, J, L$为某个索引集合。变量$i$和$j$分别编码对应锚的位置，而$l$则编码对应锚的比例，因此就能由此得到对应的锚集为$ANC^*=\left\{ \left( x_i^{an}, y_j^{an}, w_l^{an}, h_l^{an} \right)_{i\in I, j\in J, l\in L} \right\}$。然后找到$ANC^*$在$A_{w\times h\times 4k}^{cls}$的激活值来获得对应提纯坐标为$REG^*= \left\{ \left( x_i^{reg}, y_j^{reg}, dx_l^{reg}, dy_l^{reg}, dw_l^{reg}, dh_l^{reg} \right)_{i\in I, j\in J, l\in L} \right\}$。之后提炼的前$K$个提议集$PRO^*=\left\{ \left( x_i^{pro}, y_j^{pro}, w_l^{pro}, h_l^{pro} \right) \right\}$可以通过下面的公式获得：
$$
\begin{eqnarray}
x^{pro}_i &=& x_i^{an} + dx_l^{reg} * w_l^{an} \\
y^{pro}_j &=& y_j^{an} + dy_l^{reg} * h_l^{an} \\
w_l^{pro} &=& w_l^{an} * e^{dw_l} \\
h_l^{pro} &=& h_l^{an} * e^{dh_l}
\end{eqnarray}
$$
在获得这前$K$个提议后，就用一些提议选择策略来使其适于追踪任务。

##### 提议选择

为使单射检测框架适用于追踪，作者提出了两种选择提议的策略：

- 第一种是舍弃离中心太远的锚生成的边框，比如仅保留$A_{w\times h\times 2k}^{cls}$分类特征图上中心$g\times g$的子区域，这样就获得了$g\times g\times k$而非$m\times n\times k$个锚。因为临近的帧目标并不会有很大的移动，因此这种方法能有效去除异常值。如下图所示：

  <img src='figures/selection.png' />

- 第二种是使用余弦窗和尺度变化惩罚来重排提议的分数从而获得最优。在去除异常值之后，添加一个余弦窗来抑制大偏移，然后添加一个惩罚来抑制尺寸和比率的大改变：
  $$
  penalty = e^{k*max\left(\frac r{r'}, \frac{r'}r\right) * max\left( \frac s{s'}, \frac{s'}s \right)}
  $$
  这里$k$是超参，$r$表示提议的高宽比，$r'$表示上一帧提议的高宽比，$s$和$s'$则表示提议和上一帧的整体尺寸，计算方法如下：
  $$
  (w+p)\times(h+p) = s^2
  $$
  其中$w$和$h$表示目标的宽和高，$p=\frac{w+h}2$表示填充。再用暂时惩罚乘以分类分数后就的到了重排的前$K$个提议，之后执行NMS来获得最终的追踪边框。在选出最终的边框后，通过线性插值更新目标尺寸来维持形状平滑变化。



#### 附录

##### 孪生网络

孪生网络由两个分支组成，暗含将原始块编码到另一个空间，然后用一个特定张量将它们融合以产生单个输出。通常用于比较暗含嵌入空间两个分支的特征，尤其是对照任务。

##### 区域推介网络

##### 单射学习

深度学习中的单射学习正日趋引起人们的重视。