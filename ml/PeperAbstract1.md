##### Context Encoders(1604.07379)

本文展示了基于上下文像素预测驱动的视觉特征学习算法。与自编码器类似，这里提出上下文编码器——一个训练用来视周围条件产生任意图像区域内容的卷积神经网络。为了完成此任务，上下文编码器既要理解整个图像的内容，又要产生失去部分的合理假设。在训练上下文编码器时，既试验了标准像素级重建损失，也有重建外加对抗损失。后者产生了更加锐利的结果，因其能更好地处理输出中的多种模式。本文发现上下文编码器学习了一种既能抓取视觉结构表面又能抓取其语义的表示，并量化地展示了学习到的特征为分类、检测、分割预训练CNN的有效性。另外，上下文编码器也能用于语义修复的任务，既可以单独也可以作为非参方法的初始化。



##### FractalNet(1605.07648)

本文介绍一种基于自相似性的神经网络宏观结构的设计策略。简单膨胀策略的反复应用就能产生结构布局是恰好是缩短的分形(fractal)。这些网络包含不同长度的交互的子通道(path)，但不包含任何穿通或残差连接；每个内部的信号在被后面的层看到前都会被一个滤波器和一个非线性变形。在试验中，分形网络在CIFAR和ImageNet上都和标准的残差网络的优秀结果匹敌，因此表明残差表示可能并非是极端深度卷积神经网络成功必不可少的，关键而可能是在训练期间有效地从浅层向深层的转变。作者注意到学生-教师行为的相似性并开发路径丢弃(Drop-Path)，一种dropout的自然扩展，来正规化分形网络中路径的共通调节(co-adaptation)。这样的正规化允许高性能定深子网络的提取。另外，分形网络展示出一种普遍(anytime)特性：浅层子网络提供快速的回答，而有更高延迟的更深网络则提供更精确的答案。