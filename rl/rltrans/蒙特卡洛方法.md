随机算法分为两大类：拉斯维加斯(Las Vegas)算法和蒙特卡洛(Monte Carlo)算法。拉斯维加斯算法总返回精确的正确答案（或报告失败），这些算法消耗随机数量的资源，通常是内存和时间。相反，蒙特卡洛算法返回有随机误差的答案，误差量通常可以通过消耗更多资源（通常是运行时间和内存）来减少。对任意固定的计算预算，蒙特卡洛算法能提供一个近似解。许多机器学习的问题都无法获得精确解，这时必须使用确定性近似算法或蒙特卡洛估计。两种方法在机器学习中都是普适的。

##### 1.抽样与蒙特卡洛方法

机器学习中许多重要技术都是基于从某个概率分布中采样，并使用这些样本形成某些希望数值的蒙特卡洛估计。

当一个积分或求和无法精确求解时，通常很可能用蒙特卡洛采样来近似。思想是看求和或积分是否是某个分布下的期望，并用相应的均值来近似这个期望。令
$$
s=\sum_x p(x)f(x) = E_p[f(\mathbf x)]
$$
或
$$
s = \int p(x)f(x)dx = E_p[f(\mathbf x)]
$$
是要估计的求和或积分，重写为期望的形式，并限定$p$是随机变量$\mathbf x$（求和的）概率分布或（积分的）概率密度。可以通过从$p$中抽取$n$个样本$x^{(1)},\dots,x^{(n)}$并形成经验均值来估计$s$：
$$
\hat s_n = \frac{1}{n} \sum_{i=1}^n f \left( x^{(i)} \right)
$$
这个估计可以用一些不同特性验证。第一个是估计$\hat s$是无偏的，因为
$$
\mathbb E[\hat s_n] = \frac {1}{n} \sum_{i=1}^n \mathbb E\left[ f(x^{(i)}) \right]=\frac{1}{n}\sum_{i=1}^n s = s
$$
另外由大数定律，如果样本$x^{(i)}$是i.i.d（独立同分布）的，则均值几乎肯定收敛于期望值：
$$
\lim_{n \to \infty} \hat s_n = s,
$$
假设单独的方差项，$\text{Var}\left[ f(x^{(i)}) \right]$，是有界的。考虑随着$n$增加$\hat s_n$的方差。只要$\text{Var}\left[ f(\mathbf x^{(i)}) \right] < \infty$，方差$\text{Var}\left[ \hat s_n \right]$递减并收敛于0：
$$
\begin{aligned}
\text{Var}[\hat s_n]
&= \frac{1}{n^2} \sum_{i=1}^n \text{Var}[f(\mathbf x)] \\
&= \frac{\text{Var}[f(\mathbf x)]}{n}
\end{aligned}
$$
这个结果也指示了在蒙特卡洛均值或等价的蒙特卡洛近似的期望误差中如何评估不确定性。同时计算$f(x^{(i)})$的经验均值和经验方差，然后将估计的方差除以样本数以获得$\text{Var}[\hat s_n]$的估计量。由中心极限定理，均值$\hat s_n$的分布收敛于均值为$s$，方差为$\frac{\text{Var}[f(\mathbf x)]}{n}$。这样就可以使用正态密度的累积分布来估计$\hat s_n$的置信区间。

但所有这些都有赖于易于从基础分布$p(\mathbf x)$中获取样本，但并不总是如此。当从$p$中采样不可行时，替代的方案是使用重要性采样(importance sampling)。更通用的方法是构建一个收敛于感兴趣分布的估计量序列，这就是蒙特卡洛马尔可夫链(Monte Carlo Markov Chains)。