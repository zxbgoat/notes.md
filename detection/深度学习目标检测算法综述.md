在传统方法中，对象检测这一问题基本是遵循着“设计手工特征(*Hand-crafted feature*)+分类器”的思路，而且由于存在着区域搜索的步骤，所以可以认为是计算机用一个小的矩形窗口不断在图像上滑动、缩放，然后用分类器预测当前滑动窗口所在区域是否存在一个感兴趣的对象。

RCNN算法的核心思想就是对每个区域通过CNN提取特征，然后接上一个分类器预测这个区域包含一个感兴趣对象的置信度，也就是说，转换成了一个图像分类问题（类似imagenet），后面接的这个分类器可以是独立训练的svm也可以是简单的softmax分类。在RCNN论文里，作者还提到两个保证检测速度的关键点：1.所有类别的分类器共享相同的特征输入；2.与传统特征相比，深度特征维度一般比较低，比如VGG16里的4096维。

但是很可惜，即使使用了selective search等预处理步骤来提取潜在的bounding box作为输入，但是RCNN仍会有严重的速度瓶颈，原因也很明显，就是计算机对所有region进行特征提取时会有重复计算，Fast-RCNN正是为了解决这个问题诞生的，作者提出了一个可以看做单层sppnet的网络层，叫做ROI Pooling，这个网络层可以把不同大小的输入映射到一个固定尺度的特征向量。

conv、pooling、relu等操作都不需要固定size的输入，因此，在原始图片上执行这些操作后，虽然输入图片size不同导致得到的feature map尺寸也不同，不能直接接到一个全连接层进行分类，但是可以加入这个神奇的ROI Pooling层，对每个region都提取一个固定维度的特征表示，再通过正常的softmax进行类型识别。另外，之前RCNN的处理流程是先提proposal，然后CNN提取特征，之后用SVM分类器，最后再做bbox regression，而在Fast-RCNN中，作者巧妙的把bbox regression放进了神经网络内部，与region分类和并成为了一个multi-task模型，实际实验也证明，这两个任务能够共享卷积特征，并相互促进。Fast-RCNN很重要的一个贡献是成功的让人们看到了Region Proposal+CNN这一框架实时检测的希望，原来多类检测真的可以在保证准确率的同时提升处理速度，也为后来的Faster-RCNN做下了铺垫。

Fast-RCNN之后的问题已经非常清晰，就是我们能不能把region proposal部分也放到GPU上？于是有了Faster-RCNN，出现了一个end-to-end的CNN对象检测模型。作者提出，网络中的各个卷积层特征其实可以用来预测类别相关的region proposal，不需要事先执行诸如selective search之类的算法，但是如果简单的在前面增加一个专门提proposal的网络又显得不够elegant，所以最终把region proposal提取和Fast-RCNN部分融合进了一个网络模型，虽然训练阶段仍然要分多步，但是检测阶段非常方便快捷，准确率也与原来的Fast-RCNN相差不多，从此，再也不用担心region proposal提取耗时比实际对象检测还多这种尴尬场景了。

##### ROI Pooling

首先需要介绍RCNN系列里的一个核心算法模块，即ROI Pooling。我们知道在ImageNet数据上做图片分类的网络，一般都是先把图片crop、resize到固定的大小（i.e. 224*224），然后输入网络提取特征再进行分类，而对于检测任务这个方法显然并不适合，因为原始图像如果缩小到224这种分辨率，那么感兴趣对象可能都会变的太小无法辨认。RCNN的数据输入和SPPNet有点类似，并不对图片大小限制，而实现这一点的关键所在，就是ROI Pooling网络层，它可以在任意大小的图片feature map上针对输入的每一个ROI区域提取出固定维度的特征表示，保证后续对每个区域的后续分类能够正常进行。

ROI Pooling的具体实现可以看做是针对ROI区域的普通整个图像feature map的Pooling，只不过因为不是固定尺寸的输入，因此每次的pooling网格大小得手动计算，比如某个ROI区域坐标为$(x_1,y_1,x_2,y_2)$。那么输入size为$ (y_2−y_1) \times (x_2−x_1)$。如果pooling的输出size为$\text{pooled_height} \times \text{pooled_width}$，那么每个网格的size为$\frac{y2−y1}{\text{pooled_height}} \times \frac{x2−x1}{\text{pooled_width}}$。具体代码可在roi_pooling_layer.cpp中的Forward_cpu函数里找到，比较简单。作者并没有对Backward阶段实现CPU代码，所以只能在roi_pooling_layer.cu中查看，即ROIPoolBackward函数，其具体进行的操作可以用论文里的一行公式形容，
$$
\frac{\partial L}{\partial x} = \sum_{r\in R} \sum_{y\in r} [y\ \text{pooled}\ x] \frac{\partial L}{\partial y}
$$
其中 R 表示R个输入ROI区域以及对应的R个输出feature，x和y分别表示输入的feature map和输出的feature，整个公式的意思就是，"During back-propagation, derivatives flow through the RoI pooling layer. The RoI pooling layer's backwards function computes the partial derivative of the loss function with respect to each input variable x by summing over all RoIs that max-pooled x in the forward pass."，另外，由于实际实现是采用的是Max Pooling，因此y pooled x表示“x在该网格区域中最大，然后y被assign到x的值”，而具体每个网格中哪个点的值最大，也是在Forward过程中就已经记录，存储在了argmax_data变量里。

##### Bounding-box Regression

有了ROI Pooling层其实就可以完成最简单粗暴的深度对象检测了，也就是先用selective search等proposal提取算法得到一批box坐标，然后输入网络对每个box包含一个对象进行预测，此时，神经网络依然仅仅是一个图片分类的工具而已，只不过不是整图分类，而是ROI区域的分类，显然大家不会就此满足，那么，能不能把输入的box坐标也放到深度神经网络里然后进行一些优化呢？rbg大神于是又说了"yes"。在Fast-RCNN中，有两个输出层：第一个是针对每个ROI区域的分类概率预测，$p=(p_0, p_1, \cdots, p_K)$；第二个则是针对每个ROI区域坐标的偏移优化，$t^k = (t_x^k, t_y^k, t_w^k, t_h^k),\ 0 \le k \le K$是多类检测的类别序号。这里我们着重介绍第二部分，即坐标偏移优化。

假设对于类别$k^*$，在图片中标注了一个groundtruth坐标： $t^*=(t_x^*,t_y^*,t_w^*,t_h^*)$，而预测值为

