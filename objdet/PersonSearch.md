#### OIM (Joint Detection and Identification Feature Learning for Person Search)

行人重识别（Re-ID）致力于在大量行人图像中匹配出目标人物，其难点在于人体姿势的复杂变化、摄像头视角、光照、遮挡、分辨率、背景抖动等。尽管取得了巨大进展，但与实际应用仍有不小的鸿沟。大多数重识别测试基准其库中包含的是手工裁剪的行人图像，但实际应用的目标却是在全景图像中找到目标人物，如下图所示。因此大多数现有的重识别方法都假设了完美的行人检索。但实际应用中显然不存在这样的手工裁剪边框，因此现成的行人检测器不可避免会产生很多假触发、误检、不对齐等情况，这些都会严重伤害到最终的检索效果。

<img src='figures/reid-vs-search.png' width=500 />

本文提出了一种人物检索的新深度学习框架。不同于传统方法将这个问题分成行人检索和行人重识别两个任务，我们在单个卷积网络中同时解决这两方面。这个卷积网络由两部分组成，给定整个搜索场景图像，行人提议（proposal）网络会产生候选人物的边界框，然后将它们输入到坚定（identification）网络提取特来为目标人物的比较提取特征。提议网络和鉴定网络在共同优化时互相调整。例如提议网络相比正确率会更关注召回率，因为假触发可以通过后面的特征匹配过程清除；同时，提议的不对齐也变得可接受，因其可以通过鉴定网络进一步调整。为提高整个系统的扩展性，我们鼓励这两个部分基础的卷积特征图，极大加速了推理进程。

传统的重识别特征学习主要使用逐对或三元距离损失函数，但每次仅有一些数据样本被比较，而潜在的输入组合却是$O(N^2)$的，并且不同的采样策略会显著影响收敛速度和质量，因此并不十分有效；另一个用于学习分类实体的是softmax损失函数，能够有效地同时比较所有样本，但随着类别数增加，训练大的softmax分类矩阵会变得十分缓慢甚至无法收敛。本文提出了新的在线实例匹配（Online Instance Matching，OIM）损失函数，从所有标记的实体中维护一个查询表或特征，并比较批次样本和所有注册实体的距离；另一方面许多未标记的实体可能会出现在场景图像中，就可以作为标记实体的负样本；因此我们也未对比发掘了一个循环=队列来存储其特征，这是人物检索问题设定带来的另一个优势。这个无参的OIM损失收敛得比softmax损失更快更好。

这个工作主要由三个贡献：一是提出了一种新的深度学习框架来从整个场景图中搜索目标人物，并在单个卷积网络中同时优化检测和重识别这两个任务以使它们更好地互相调整；二是提出了OIM损失函数来更有效地学习鉴定特征，使得这个框架能够扩展到含有海量实体的大数据集，伴随着更快的推理速度，我们的框架进一步满足了实际应用的要求；最后我们为人物检索收集并标注了大规模的基准测试数据集，包含了来自街道和电影快照中的数百个场景，数据集包含18184张图像、8432个实体、以及96143个行人边界框。

##### 方法

整个框架如下图所示。给定输入场景图像，我们首先使用主干卷积网络提取特征，再次之上构建一个提议网络来预测候选人物的边界框，然后再使用RoI池化来输入鉴定网络来为每个候选提取L2正规化的256维特征；在推理阶段，我们依据到目标人物的特征距离来排序候选人物；而训练阶段则在特征向量之上使用OIM损失函数来监督验证网络，伴随着其他几个损失函数来以多任务的形式训练提议网络。